{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553cb2fb-71ca-407c-ac55-d9eb10588ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abec13d-ed42-40e4-9022-c795da5424d3",
   "metadata": {},
   "source": [
    "Let's use the tools we've learned so far and the model one type we've learned to see how the modeling process works. In other words:\n",
    "\n",
    "# You made a model, now what?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb62d47-f957-4b09-89c4-841fdd229f04",
   "metadata": {},
   "source": [
    "### Lab Two Questions?\n",
    "\n",
    "Note the difference between the two models:\n",
    "\n",
    "$$\n",
    "Y_{mass} = \\beta_0 + \\beta_1 X_{flipper} + \\beta_2 X_{is\\_male}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Y_{mass} = \\beta_0 + \\beta_1 X_{flipper} + \\beta_2 X_{is\\_male} + \\beta_3 X_{flipper} X_{is\\_male}\n",
    "$$\n",
    "\n",
    "- Why might we want this extra term? What happens in these models when $X_{is\\_male} = 0$ vs. $= 1$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59fc56-695f-4bfb-ab03-7031c4138abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penguins = sns.load_dataset('penguins')\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4354db2a-966a-4d52-af83-eed68202e3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d716601c-7f2f-4c95-bd86-1faeb12647fc",
   "metadata": {},
   "source": [
    "## Metrics vs. Loss\n",
    "\n",
    "- In Machine Learning the **Loss Function** refers to the quantity used to *optimize* or create the model. Usually the loss function is minimized (This is just by convention; minimization is equivalent to maximizing the negative of a real-valued function).\n",
    "- A **Metric** is the quantity used to *evaluate* the model. Usually this is the quantity we really care about.\n",
    "\n",
    "### Example\n",
    "- Predict whether a penguin's body mass is higher than average using Linear Regression.\n",
    "- (We could also use Logistic Regression, but that's for next time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6f0ad-ac79-430b-9f1e-aa0bc183458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean body mass is {df_penguins[\"body_mass_g\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd061b4-cfa2-43a2-ab39-fc95802fbae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_penguins['body_mass_g'])\n",
    "plt.axvline(x=df_penguins[\"body_mass_g\"].mean(), color='red')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa2d168-5a67-4d68-af9e-9d37743ca762",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_penguins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613b581-13b5-4410-beb8-1360c2406cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penguins.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea22f915-b320-4bed-be9a-17fb2497eacd",
   "metadata": {},
   "source": [
    "Looks like many of the features are somewhat linearly correlated.. Let's throw them all in a model and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452645aa-6d0f-4147-b465-35605bec2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(formula = 'body_mass_g ~ flipper_length_mm + bill_depth_mm + bill_length_mm', data=df_penguins)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a74f128-56e9-400a-8ace-4bed9f3c7676",
   "metadata": {},
   "source": [
    "- What is the Loss Function here?\n",
    "- What might you use for a Metric if we care about predicting body mass accurately?\n",
    "\n",
    "### An aside:\n",
    "- For OLS, minimizing RSS is the same as maximizing $R^2$. Recall:\n",
    "\n",
    "$$\n",
    "RSS = \\frac{TSS - RSS}{TSS}.\n",
    "$$\n",
    "\n",
    "Even in this case, I would call $R^2$ a metric because:\n",
    "- In my final report I would record the $R^2$ value.\n",
    "- I would compare the $R^2$ value with another model created in another way (maybe something fancy like a decision tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea58ba-4d3a-4b41-9516-a837946578dc",
   "metadata": {},
   "source": [
    "### Adjusted R^2\n",
    "\n",
    "Let $n$ be the number of samples and $k$ be the number of features, then\n",
    "\n",
    "$$\n",
    "Adj \\,\\, R^2: 1 - (1-R^2)\\frac{(n-1)}{(n-k-1)}\n",
    "$$\n",
    "- Think about what happens when $k$ increases. How does $n$ affect this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb851d-0617-4332-a01f-7c69c8d4bc36",
   "metadata": {},
   "source": [
    "Let's move on to predicting whether a penguin \"is heavier\" or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7184978-5c47-4446-83d2-58c2a9e46ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new variable\n",
    "# do you see any problems below?\n",
    "df_penguins['is_heavier'] = df_penguins['body_mass_g'] >  df_penguins[\"body_mass_g\"].mean()\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d587536-5dc0-428d-86bd-712cf8a7ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the problem here!\n",
    "df_penguins.dropna(inplace=True)\n",
    "df_penguins.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076809ca-ce7e-4a51-884c-4174db1f9af3",
   "metadata": {},
   "source": [
    "Now what I *care* about is how well I predict my new variable ```is_heavier```. I no longer care about $R^2$ but maybe about **Accuracy** which is the ratio of correct predictions with the total amount of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e061c4f7-9ae4-4352-8c58-975d3dcc8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how accurate this model is\n",
    "y_pred = res.predict(df_penguins)\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c749a5-27aa-4903-a5e7-bc2d28ec93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred > df_penguins[\"body_mass_g\"].mean()\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6270fa6-cf68-469c-8589-a07d89f032c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of correct predictions\n",
    "# think about why!\n",
    "correct = sum(y_pred == df_penguins['is_heavier'])\n",
    "accuracy = correct / len(y_pred)\n",
    "print(f'This model has accuracy: {100*accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0432951-a389-467a-85bd-2e05cfc2d145",
   "metadata": {},
   "source": [
    "- Nothing about the model has changed. Notice how the metric we use determines how we feel about the model.\n",
    "- Other important metrics surround classification are **Precision** and **Recall** (More on this next week).\n",
    "- The Confusion Matrix is very helpful to understand why a binary classification model might be classifying things the way it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd589944-c255-4d52-8946-0f732e8c50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2567e3-7d2d-48f4-b7ee-8cf5fc511a70",
   "metadata": {},
   "source": [
    "- Well how can we improve this model?\n",
    "\n",
    "## Feature Engineering\n",
    "- We can think of what we did in Lab 2 as Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17360528-1b21-429f-bca0-81d8fe29bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penguins['is_male'] = df_penguins['sex'].apply(lambda x : int(x == 'Male'))\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba6e4b-54ea-453d-bb2d-2361f4b7b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model = ols(formula = 'body_mass_g ~ flipper_length_mm + bill_depth_mm + bill_length_mm', data=df_penguins)\n",
    "res = model.fit()\n",
    "\n",
    "# predict\n",
    "y_pred = res.predict(df_penguins)\n",
    "y_pred = y_pred > df_penguins[\"body_mass_g\"].mean()\n",
    "\n",
    "# evaluate\n",
    "correct = sum(y_pred == df_penguins['is_heavier'])\n",
    "accuracy = correct / len(y_pred)\n",
    "print(f'This model has accuracy: {100*accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c55d3-7310-476d-a1e1-76c5d1659ee4",
   "metadata": {},
   "source": [
    "Let's go back to the Ads dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afabbab0-d7d8-454f-a050-01dca28f2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ads = pd.read_csv('data/Advertising.csv')\n",
    "df_ads.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d9fac-5852-43e6-bc65-1584785e914b",
   "metadata": {},
   "source": [
    "We want to predict sales so let's look at that bottom row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e461bc-174c-41f2-b012-8b801a5cf9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574b167-216a-4f4e-a8ef-33e12c9e42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tv isn't exactly linear, but looks more like a square root function\n",
    "df_ads['TV_root'] = df_ads['TV']**(1/3)\n",
    "\n",
    "plt.scatter(x=df_ads['TV'], y=df_ads['sales'])\n",
    "plt.title('TV vs. Sales')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x=df_ads['TV_root'], y=df_ads['sales'])\n",
    "plt.title('Root of TV vs. Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134def65-f71b-4698-b27e-217ca9b0b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see slight improvement in the correlation matrix\n",
    "df_ads.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c93be-d0ed-4edc-aff8-3d0245a728ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(formula = 'sales ~ TV', data=df_ads)\n",
    "res = model.fit()\n",
    "print(f' The R^2 using TV is {res.rsquared}')\n",
    "\n",
    "model = ols(formula = 'sales ~ TV_root', data=df_ads)\n",
    "res = model.fit()\n",
    "print(f' The R^2 using square root of TV is {res.rsquared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c003dfa-857c-45af-a972-4c8c1664bfb1",
   "metadata": {},
   "source": [
    "Polynomial Regression is just linear regression with new features!\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95611281-97c6-4e2f-ae07-e41a4f974e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset you will working with for HW2\n",
    "df_taxis = sns.load_dataset('taxis')\n",
    "df_taxis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423593e-a146-4d90-8057-28190ff0ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxis['pickup'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef5926d-a689-4ffc-83c7-3fc9237419f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time datatype!\n",
    "pd.to_datetime(df_taxis['pickup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979840d8-906e-434b-bf92-9a4f89db92bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time delta\n",
    "pd.to_datetime(df_taxis['dropoff']) - pd.to_datetime(df_taxis['pickup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f09ed8-80ac-41b1-baf1-398aff220d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.to_datetime(df_taxis['dropoff']) - pd.to_datetime(df_taxis['pickup'])\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8598e2-4eeb-46b8-a233-43e07a39e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a new feature: length of trip!\n",
    "# converting to minutes\n",
    "df_taxis['length_of_trip'] = delta / pd.Timedelta('60s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b86ec-93ce-48ac-a787-16210babad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df_taxis['length_of_trip'], y=df_taxis['total'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31b048e-595c-4d9a-9954-549ac7434d56",
   "metadata": {},
   "source": [
    "How about a new categorical feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d945478-a99d-40ba-b7e7-e3e8bc1a08a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wow there's a lot!\n",
    "len(df_taxis['pickup_zone'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd84582-e8f0-4f65-a98b-8b7187c695f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which is the most frequented?\n",
    "from collections import Counter\n",
    "\n",
    "sorted_list = Counter(df_taxis['pickup_zone']).most_common()\n",
    "print(sorted_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877cbdd3-c1b8-4255-b317-f776f04dbedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxis['pickup_zone_Midtown'] = df_taxis['pickup_zone'].apply(lambda x : x == 'Midtown Center')\n",
    "df_taxis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf0cdc2-dfc7-47b7-b7bc-274a12117fcd",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "- Remember to be careful of outliers!\n",
    "- Below we have vote counts for various counties in Florida from the 2000 Presidential Election.\n",
    "\n",
    "Context:\n",
    "- In the 2000 USA Presidential election, Florida was the \"tipping point\" state for Bush, meaning that, after ranking the states by margin of victory, Florida was the state that gave Bush enough electoral votes to win the election.\n",
    "- Additionally, holding all other state results constant, if Gore had won Florida then the election would have flipped to Gore.\n",
    "- Also Bush only won the state by 537 votes out of a total 6,000,000 cast 😳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c1afdb-2a09-4a8b-b46d-c0b9db78f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votes = pd.read_csv('data/2000FL_votes.csv')\n",
    "df_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e493669a-3ca2-47be-81d2-96d5ca79fdd3",
   "metadata": {},
   "source": [
    "More context\n",
    "- Pat Buchanan was another conservative candidate with a similar platform as George W. Bush.\n",
    "- Counties with a large number of conservative voters would likely see more votes for both Bush and Buchanan\n",
    "- We can expect to see some correlation here between the two vote counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed6413-733a-4a29-9095-b9d7db7087ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df_votes['George W. Bush'], y=df_votes['Pat Buchanan'])\n",
    "plt.xlabel('Bush Votes')\n",
    "plt.ylabel('Buchanan Votes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3012d8c5-e1ff-4e9a-8c50-8ca194944c41",
   "metadata": {},
   "source": [
    "Controversy!\n",
    "- But wait what is that?\n",
    "- The county of Palm Beach used what were called [Butterfly Ballots](https://upload.wikimedia.org/wikipedia/commons/4/4e/Butterfly_Ballot%2C_Florida_2000_%28large%29.jpg).\n",
    "- The claim is that many Gore voters accidentally voted for Pat Buchanan. (Research paper [here](https://www.gsb.stanford.edu/faculty-research/publications/butterfly-did-it-aberrant-vote-buchanan-palm-beach-county-florida) giving evidence for this claim)\n",
    "\n",
    "Pay attention to the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b938c50-6620-412d-8190-2e811fd62a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='George W. Bush', y='Pat Buchanan', data=df_votes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0070c6f-1439-49bc-a978-130ccfaba0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove palm beach\n",
    "df_votes_nopb = df_votes[df_votes['county'] != 'PALM BEACH']\n",
    "\n",
    "sns.lmplot(x='George W. Bush', y='Pat Buchanan', data=df_votes_nopb)\n",
    "\n",
    "# keep same x,y limits\n",
    "plt.xlim(min(df_votes['George W. Bush']), max(df_votes['George W. Bush']))\n",
    "plt.ylim(min(df_votes['Pat Buchanan']), max(df_votes['Pat Buchanan']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8626b6-3be5-4035-b9d7-10ed4e4ad7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(formula = 'PB ~ GWB', data=df_votes.rename(columns={'Pat Buchanan': 'PB',\n",
    "                                                                'George W. Bush': 'GWB'}))\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff4edd4-bf44-420c-8aa8-b75f236dce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(formula = 'PB ~ GWB', data=df_votes_nopb.rename(columns={'Pat Buchanan': 'PB',\n",
    "                                                                'George W. Bush': 'GWB'}))\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7aa28-57a9-4150-aaa1-45a931cc811f",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Look how small that coefficient is! Is there a relationship between Bush and Buchanan votes? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee109f9-4787-4e98-9690-25d765e02006",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "How well does my model perform on unseen data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8469640f-95b2-4913-a28d-ab2483fe9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penguins.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b01ae-9926-416f-bef7-ab2ab67017ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(formula = 'body_mass_g ~ flipper_length_mm', data=df_penguins)\n",
    "res = model.fit()\n",
    "print(f'This model has an R^2 of {res.rsquared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27983cdd-4551-4c21-9889-75c7a83bb590",
   "metadata": {},
   "source": [
    "What about penguin data points not used to build the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de380ec-b80c-42d3-a566-6dda9a23969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# take random 10% of the penguins for testing\n",
    "train, test = train_test_split(df_penguins, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13cbc0-a895-4aa6-ba18-7c595fe9622d",
   "metadata": {},
   "source": [
    "- This is a **Train**-**Test** split. The training set is used to create the model while the test set is used to evaluate the model.\n",
    "- The test set is \"unseen\" data for the model. It did not \"know\" what the RSS values were for these penguins during model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce8d1f-41e7-42eb-8332-1f307d05ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model on training set\n",
    "model = ols(formula = 'body_mass_g ~ flipper_length_mm', data=train)\n",
    "res = model.fit()\n",
    "\n",
    "# predict using the model\n",
    "y_pred = res.predict(test)\n",
    "\n",
    "# score the model\n",
    "y = test['body_mass_g']\n",
    "y_mean = train['body_mass_g'].mean()  # use the mean of the training set\n",
    "\n",
    "TSS = sum((y_pred - y_mean)**2)\n",
    "RSS = sum((y_pred - y)**2)\n",
    "print(f'This model has an R^2 on the test set of {(TSS - RSS) / TSS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088a897-0df3-4238-9f35-af0cabe0b549",
   "metadata": {},
   "source": [
    "- Why did it go down?\n",
    "- Is this bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e67ab-e51a-4dbb-9a79-a30d64e48bb9",
   "metadata": {},
   "source": [
    "## Under/Overfitting\n",
    "\n",
    "There are two problems one often faces with a train-test split:\n",
    "- Overfitting: The model performs well on training data, but the model performs poorly on the test data\n",
    "- Underfitting: The model performs poorly on the training data\n",
    "\n",
    "This is related to the *Bias-Variance Tradeoff* which we will discuss in Lecture 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e8888e-c24c-4057-abc3-780d5da334a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make some fake nonlinear data to illustrate this\n",
    "num_pts = 40\n",
    "x = np.linspace(-2, 2, num_pts)\n",
    "\n",
    "# noise\n",
    "epsilon = np.random.normal(0, 3, num_pts)\n",
    "\n",
    "# degree 3 polynomial\n",
    "y = 3*(x-1)*(x+2)*(x-1.5) + epsilon\n",
    "\n",
    "plt.scatter(x=x, y=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542ad1f-fdc3-4bce-be73-f727eb358803",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, sm.add_constant(x), hasconst=True)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fd47f-3876-4588-8085-f8fd94b42c8d",
   "metadata": {},
   "source": [
    "We can see from the $R^2$ and visually that the line is underfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5906a3-209c-4323-92d7-08294a2ea04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, m = res.params\n",
    "\n",
    "plt.scatter(x=x, y=y)\n",
    "\n",
    "plt.axline((0, b), slope=m, color='green')\n",
    "\n",
    "plt.xlim(min(x), max(x))\n",
    "plt.ylim(min(y), max(y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7aca1b-d542-4bab-be91-97f356e0562d",
   "metadata": {},
   "source": [
    "Now let's do some feature engineering. Let's create polynomial features and do a linear regression (polynomial regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a3535-833e-4902-95e5-60182d3c148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "n = 30\n",
    "\n",
    "for i in range(n-1):\n",
    "    df[f'x_{i+2}'] = x**(i+2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db3301-cc3f-41ff-a903-c268c92a2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_var = 'x'\n",
    "for i in range(n-1):\n",
    "    indep_var = indep_var + f' + x_{i+2}'\n",
    "print(indep_var)\n",
    "\n",
    "model = ols(formula = f'y ~ {indep_var}', data=df)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f4ed6-e271-48e6-8988-9949f6be2a66",
   "metadata": {},
   "source": [
    "Looks like a good $R^2$! But wait one second.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a396e21-ac5e-42ad-bb59-39032d3c4e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=x, y=y)\n",
    "\n",
    "# plot the polynomial\n",
    "coefs = list(res.params)\n",
    "coefs.reverse()\n",
    "poly = [np.polyval(coefs, i) for i in x]\n",
    "plt.plot(x, poly)\n",
    "\n",
    "plt.xlim(min(x), max(x))\n",
    "plt.ylim(min(y), max(y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1cf639-5756-4901-a68c-fb05c84efbdb",
   "metadata": {},
   "source": [
    "That doesn't seem right.. What happens if create a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43feb541-536d-4217-8956-cf15b08aad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.linspace(-2,2,num_pts)\n",
    "epsilon = np.random.normal(0,3,num_pts)\n",
    "\n",
    "# degree 3 polynomial\n",
    "y_test = 3*(x_test-1)*(x_test+2)*(x_test-1.5) + epsilon\n",
    "\n",
    "plt.scatter(x=x_test, y=y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae7e781-8f76-40be-8ca5-6bb69882c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=x_test, y=y_test)\n",
    "\n",
    "plt.plot(x, poly)\n",
    "\n",
    "plt.xlim(min(x_test), max(x_test))\n",
    "plt.ylim(min(y_test), max(y_test))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5709a-0ba8-4038-ba2a-b73a8eaa85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = y.mean()\n",
    "y_pred = [np.polyval(coefs, i) for i in x_test]\n",
    "\n",
    "tss = sum((y_test - train_mean)**2)\n",
    "rss = sum((y_test - y_pred)**2)\n",
    "\n",
    "r2 = (tss - rss) / tss\n",
    "print(f'The R squared for this model is {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4762323-1124-4d80-a8b7-5fcd4db7736b",
   "metadata": {},
   "source": [
    "We want to find that sweet spot between underfitting and overfitting!\n",
    "- **Cross Validation**: Split the dataset into disjoint pieces. Use each piece as a **validation** set and train the model on the rest of the data. Average the metrics over the pieces.\n",
    "- $k$-fold: split training set into $k$ equal, disjoint sets.\n",
    "- Leave Out One Cross Validation (LOOCV): Each data point is a piece.\n",
    "- **Bootstrapping**: Do this *with replacement* rather than disjoint pieces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6206240-0f8d-4114-8781-69b2b8fc5065",
   "metadata": {},
   "source": [
    "### Data Leakage\n",
    "- Why train, *validation*, test split?\n",
    "- **Data Leakage in Machine Learning** is when information about the test set used to evalute the model or the target variable *leaks* into the modeling process.\n",
    "\n",
    "Let's say I create a test set from my training data, and I run a linear regression. The $R^2$ isn't where I hoped, so I remove some outliers from the training data. It goes up! Great. Now I engineer 5 features. I see which of these features improves the $R^2$ the most on the test set, and decide to keep that one in my model. My final model is created on the training set with the outliers removed and my best engineered feature. I report the $R^2$ of this model's predictions on the test set.\n",
    "\n",
    "- Why can't I trust these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ddbaa1-a5dd-4b3c-822d-cabcfa497302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which of these variables\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6098076-9b9a-4331-822f-0f9918aba014",
   "metadata": {},
   "source": [
    "If I'm creating a model to predict penguin weight in a zoo, then maybe I won't know what ```island``` a penguin is from! In this case invalid information about the target variable has leaked into the model if I use ```island``` since I won't have this information when used in reality. My model will be overly confident."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
