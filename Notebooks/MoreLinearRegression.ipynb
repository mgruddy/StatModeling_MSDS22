{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193fdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc5a0c",
   "metadata": {},
   "source": [
    "Remember our fuel efficiency dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2558858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv')\n",
    "df_cars.dropna(inplace=True)\n",
    "df_cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd334f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get line of best fit\n",
    "model = ols(formula = 'horsepower ~ weight', data=df_cars)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b244c251-17ee-4a80-a234-011fea444345",
   "metadata": {},
   "source": [
    "Remember if you are on Colab:\n",
    "\n",
    "```!pip install matplotlib==3.5```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe508b2-662b-426d-b4fe-95a8acf36a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get the parameters from the model this way as a pandas Series\n",
    "res.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3be89f-b7da-44f6-834e-e1bcb2587f15",
   "metadata": {},
   "source": [
    "Line of best fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79c591-046a-49f1-827d-e7f8d5ea5e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, m = res.params\n",
    "\n",
    "# plot the points\n",
    "plt.scatter(x=df_cars['weight'], y=df_cars['horsepower'])\n",
    "\n",
    "# plot the line\n",
    "plt.axline((0, b), slope=m, color='green')\n",
    "\n",
    "# set limits of the axes (need to do this because we specified the y-int)\n",
    "plt.xlim(min(df_cars['weight']), max(df_cars['weight']))\n",
    "plt.ylim(min(df_cars['horsepower']), max(df_cars['horsepower']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18aad3e-c925-47e6-9500-6811c660696c",
   "metadata": {},
   "source": [
    "Below we plot the *residual* of a random point with the line of best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d71e595-5e3f-4d8b-8c05-ce52065ef565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a random point\n",
    "idx3 = np.random.randint(low=1, high=len(df_cars)+1, size=1)\n",
    "\n",
    "# use .item() to get just the value not a Series object\n",
    "x3 = df_cars.loc[idx3, 'weight'].item()\n",
    "y3 = df_cars.loc[idx3, 'horsepower'].item()\n",
    "\n",
    "# plot this point\n",
    "plt.scatter(x=x3, y=y3)\n",
    "\n",
    "# plot the line\n",
    "plt.axline((0, b), slope=m, color='green')\n",
    "\n",
    "# set limits of the x-axis (need to do this because we specified the y-int)\n",
    "plt.xlim(min(df_cars['weight']), max(df_cars['weight']))\n",
    "plt.ylim(min(df_cars['horsepower']), max(df_cars['horsepower']))\n",
    "\n",
    "# plot the prediction vs. the true value\n",
    "y_pred = m * x3 + b\n",
    "plt.plot([x3,x3], [y3, y_pred], color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e91cf4-889b-4db7-8ec6-242ebcf25476",
   "metadata": {},
   "source": [
    "## Residuals\n",
    "\n",
    "Assume a linear model\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X\n",
    "$$\n",
    "\n",
    "and data $\\{(x_1,y_1), \\dots, (x_N, y_N)\\}$. For a particular $x_i$ let $\\hat{y}_i$ be the prediction, i.e. $\\beta_0 + \\beta_1 x_i$.\n",
    "\n",
    "- The residuals are given by $\\{ \\hat{y}_1 - y_i, \\hat{y}_2 - y_2, \\dots, \\hat{y}_N - y_N\\}$\n",
    "- We optimize against the sum of the squared residuals (RSS)\n",
    "\n",
    "$$\n",
    "RSS = \\sum_{i=1}^N (\\hat{y}_i - y_i)^2\n",
    "$$\n",
    "\n",
    "- Sometimes you will hear about the **M**ean **S**quared **E**rror, MSE, (or **R**oot **M**ean **S**quared **E**rror, RSME). What happens if we optimize against either of these quantities?\n",
    "\n",
    "$$\n",
    "MSE = \\frac{\\sum_{i=1}^N (\\hat{y}_i - y_i)^2}{N} = \\frac{RSS}{N}, \\,\\,\\,\\,\\,\\, RMSE = \\sqrt{MSE}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cfad7a-a5f4-4901-99f7-ae07127f6658",
   "metadata": {},
   "source": [
    "## What are we doing really?\n",
    "\n",
    "- A **Regression** Model is concerned with how a variable $Y$ varies with respect to another input variable (or variables!) $X$.\n",
    "- What is the probability distribution of $Y$ for a particular value of $X$?\n",
    "- So what does *linear* regression really mean?\n",
    "\n",
    "We assume that our variables are related by the following expression\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X + \\epsilon\n",
    "$$\n",
    "\n",
    "where we the value of $\\epsilon$ is normally distributed with mean 0 for each particular value of $X$.\n",
    "\n",
    "- What does this mean? Does this make sense for a real-life scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30673179-49c2-4bb4-a784-864c797d9bda",
   "metadata": {},
   "source": [
    "## Assumption 1: Linear Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c606f8-c5cf-46a6-8631-0f07dc020d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data that follows this relationship\n",
    "m = 1\n",
    "b = 0\n",
    "\n",
    "num_pts = 100\n",
    "\n",
    "# create num_pts points equally spaced from 0 to 100\n",
    "X = np.linspace(0, 100, num_pts)\n",
    "\n",
    "# Gaussian noise\n",
    "mu, sigma = 0, 5\n",
    "epsilon = np.random.normal(mu, sigma, num_pts)\n",
    "\n",
    "# adding random noise to each prediction\n",
    "Y = m * X + b + epsilon\n",
    "\n",
    "plt.scatter(x=X, y=Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d35548-3505-43ac-bb57-621aa88faf04",
   "metadata": {},
   "source": [
    "- How does changing the standard deviation change the plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34862227-e6ac-4bdd-b94e-cf0c2e432c1d",
   "metadata": {},
   "source": [
    "The **Pearson Correlation Coefficient** is a statistical measure of the <i>strength of the linear relationship</i> between $Y$ and $X$:\n",
    "\n",
    "$$\n",
    "\\rho = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y} = Cor(X,Y)=\\frac{\\sum((x_i-\\overline{x})(y_i-\\overline{y})}{\\sqrt{(x_i-\\overline{x})^2}\\sqrt{(y_i-\\overline{y})^2}}\n",
    "$$\n",
    "\n",
    "\"Normalized Covariance of X and Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88556e2f-1047-48de-8ffe-d0389bb904a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs the pearson correlation ceofficient between each pair of variables\n",
    "df_cars.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897b7bf-3885-484e-9553-271d9d0bd847",
   "metadata": {},
   "source": [
    "- What do you notice about this matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdbeae8-265a-4ea1-9ae7-55c790154492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way of computing it\n",
    "np.corrcoef(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9839cfbc-e74b-4160-badf-25489a020a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also look at the fitted values vs. the residual values\n",
    "Y_pred = m * X + b\n",
    "residuals = Y_pred - Y\n",
    "\n",
    "plt.scatter(Y_pred, residuals)\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90874b9e-38b2-46ee-b33f-6aefa69e3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens for non-linear data?\n",
    "X = np.linspace(0, 15, 100)\n",
    "\n",
    "# Gaussian noise\n",
    "mu, sigma = 0, 10\n",
    "epsilon = np.random.normal(mu, sigma, num_pts)\n",
    "\n",
    "# a parabola\n",
    "Y2 = X**2 + epsilon\n",
    "\n",
    "plt.scatter(X, Y2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571544b-ad13-4146-8ae6-879e9529bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the line of best fit\n",
    "# another version of OLS for numpy data\n",
    "model = sm.OLS(Y2, sm.add_constant(X), hasconst=True)\n",
    "res = model.fit()\n",
    "b, m = res.params\n",
    "\n",
    "# plot the points\n",
    "plt.scatter(x=X, y=Y2)\n",
    "\n",
    "# plot the line\n",
    "plt.axline((0, b), slope=m, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1301a404-461f-45a9-9bf8-b97f5412da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a relationship between the residuals and the value of X!\n",
    "# oh no!\n",
    "\n",
    "Y_pred = m * X + b\n",
    "residuals = Y_pred - Y2\n",
    "\n",
    "plt.scatter(Y_pred, residuals)\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b0a4c4-e732-4d9b-bc71-6a2b8c5b0f37",
   "metadata": {},
   "source": [
    "## Assumption 2: Homoskedascity\n",
    "- The error $\\epsilon$ is normally distributed with mean 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623910f8-92c3-43f4-bd4f-272bb578a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to our fake data\n",
    "m = 1\n",
    "b = 0\n",
    "\n",
    "num_pts = 100\n",
    "\n",
    "# create num_pts points equally spaced from 0 to 100\n",
    "X = np.linspace(0, 100, num_pts)\n",
    "\n",
    "# Gaussian noise\n",
    "mu, sigma = 0, 5\n",
    "epsilon = np.random.normal(mu, sigma, num_pts)\n",
    "\n",
    "# adding random noise to each prediction\n",
    "Y = m * X + b + epsilon\n",
    "\n",
    "plt.scatter(x=X, y=Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12fab7-1f9f-4369-9206-9c51ccaece66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also look at the fitted values vs. the residual values\n",
    "Y_pred = m * X + b\n",
    "residuals = Y_pred - Y\n",
    "\n",
    "plt.hist(residuals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28086b3-d467-479f-b24d-99beee44f65b",
   "metadata": {},
   "source": [
    "The following is a Q-Q plot or (Probability Plot since we are comparing against a theoretical distrbution) which plots the ordered residuals against an ordered sample of normally distributed points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bca1b9-059f-4f7f-8c9a-5356ab28da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,8))\n",
    "sm.qqplot(residuals,line='s',ax=ax) \n",
    "\n",
    "# Normals go on the x-axis\n",
    "plt.xlabel(\"Normal Quantiles\", fontsize=16)\n",
    "\n",
    "# Residuals on the y-axis\n",
    "plt.ylabel(\"Residual Quantiles\", fontsize=16)\n",
    "\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eebe2ee-6a24-45c4-b160-b66b3adea84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is epsilon is distributed differently??\n",
    "\n",
    "# Gaussian noise\n",
    "epsilon = np.random.exponential(scale=10, size=num_pts)\n",
    "\n",
    "# adding random noise to each prediction\n",
    "Y = m * X + b + epsilon\n",
    "\n",
    "plt.scatter(x=X, y=Y)\n",
    "plt.axline((0, b), slope=m, color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be9091-4096-43f3-a1e0-2b7943174f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = m * X + b\n",
    "residuals = Y_pred - Y\n",
    "\n",
    "plt.hist(residuals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79bfa27-5ea3-470e-b2b3-c9890f3a4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,8))\n",
    "sm.qqplot(residuals,line='s',ax=ax) \n",
    "\n",
    "# Normals go on the x-axis\n",
    "plt.xlabel(\"Normal Quantiles\", fontsize=16)\n",
    "\n",
    "# Residuals on the y-axis\n",
    "plt.ylabel(\"Residual Quantiles\", fontsize=16)\n",
    "\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f262102-a3a0-4f59-91b9-a83efb0192c0",
   "metadata": {},
   "source": [
    "## Let's take a break and look at some real data.\n",
    "- Use what you've learn to identify two variables in the ```diamonds``` dataset which seems to satisfy these two assumptions and two variables which do not seem to satisfy them. Use visual evidence and statistical evidence to support your claim!\n",
    "- Food for thought: Will I get the same line of best fit if I use squared residuals vs. absolute value of residuals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90beb5a-af46-4a08-86ad-1f07b548f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dia = sns.load_dataset('diamonds')\n",
    "df_dia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5392f4-61c2-4af8-99b7-a4f69abe7240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fade0085-2edd-43b0-914e-7f260f00e569",
   "metadata": {},
   "source": [
    "## Why Squared Residuals anyways?\n",
    "* Given the assumptions above, the Gauss-Markov theorem says that the OLS estimator is BLUE (the **B**est **L**inear **U**nbiased **E**stimator).\n",
    "* The OLS estimator hits the mean for the distribution of $Y$ for each fixed value of $X$.\n",
    "* Assuming this error distribution, what are the values of $\\beta_0$ and $\\beta_1$ that maximize the probability that we would see these sample values? This is known as the **M**aximum **L**ikelihood **E**stimate or MLE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5e910-7a9d-454a-81b3-1f87a56aa5ff",
   "metadata": {},
   "source": [
    "These assumptions are also necessary to do a Hypothesis Test. The default assumption is that there is no linear correlation between two variables.\n",
    "$$\n",
    "H_0: \\beta_1 = 0 \\\\\n",
    "H_1: \\beta_1 \\neq 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3361187-478a-4d4f-bbe0-c55af7e459e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like 0 is not in the 95% confidence interval, hooray!\n",
    "model = ols(formula = 'horsepower ~ weight', data=df_cars)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5296a-d0f9-4cd7-aa1b-125eeef0ecbf",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "- More variables, more fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a0164-6408-4642-83d3-5a7eba98a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to predict horsepower again\n",
    "# why might we want to use multiple variables?\n",
    "sns.pairplot(df_cars.drop(columns=['cylinders', 'model_year']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5232d405-7349-4394-9b33-b889a00b5d8d",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "For input variables $X_1, \\dots, X_n$ we have the model\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_n X_n,\n",
    "$$\n",
    "\n",
    "or more formally\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_n X_n + \\epsilon\n",
    "$$\n",
    "\n",
    "where epsilon is normally distributed with mean 0 for any fixed tuple of values. The OLS Estimate is still obtained by minimizing the RSS function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22f144-477b-4a60-865b-7c131d2313bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the OLS estimator\n",
    "model = ols(formula = 'horsepower ~ weight + displacement', data=df_cars)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd49333-7d2c-4c71-bd01-ee5bec263213",
   "metadata": {},
   "source": [
    "- What happened to the $R^2$ when we included more variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbf5dab-20fb-48fc-9cc9-7946b7b5e843",
   "metadata": {},
   "source": [
    "## Assumption 3: No Multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77ca6e-ebcf-4c3a-afc4-e7f6f8800341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.drop(columns=['cylinders', 'model_year']).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5131fe-6d44-47f7-9b5f-dcc48fc42cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a nicer display\n",
    "sns.heatmap(df_cars.drop(columns=['cylinders', 'model_year']).corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7ad64-5c3a-4cc5-9098-6b7d72c05928",
   "metadata": {},
   "source": [
    "Why might this induce issues?\n",
    "- Violates model assumptions (can't use statistical rigor).\n",
    "- Interpreting the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd108f6-dd9e-4f0c-8eea-e8953388586a",
   "metadata": {},
   "source": [
    "### The F-Test\n",
    "Score for the Hypothesis test: \n",
    "$$\n",
    "H_0 : \\beta_1=\\beta_2=\\cdots =\\beta_p=0,\\\\\n",
    "H_1 : \\text{at least one $\\beta_i\\neq 0$}.\n",
    "$$\n",
    "All our assumptions must be satisfied for this to be valid!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb73fc5-2104-4ae4-9dec-c418cd1d981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how can we interpret this?\n",
    "model = ols(formula = 'horsepower ~ weight + displacement', data=df_cars)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24dc5c-5539-4dce-8932-a594e918ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b761d058-61d4-4ae0-bfac-138f71fc9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at using carat and depth to predict diamond price\n",
    "# I'm going to take a sample to make this harder!\n",
    "df = df_dia.sample(n=100).drop(columns=['cut','color','clarity','table', 'x', 'y', 'z'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2238706-39f4-48ad-9136-cde0e2382d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16438a55-096e-434f-ba0d-04c4ca727d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(formula = 'price ~ depth + carat', data=df)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c0f646-cea7-455e-a3ab-5146efcfd599",
   "metadata": {},
   "source": [
    "- Does this mean that we can conclude that ```depth``` is a good predicter here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792225bf-e1ed-4bd8-b73f-e9a44c1eaa68",
   "metadata": {},
   "source": [
    "## Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebfc89-4676-4e5a-8a85-0a3893ba92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to the penguins!\n",
    "df_penguins = sns.load_dataset('penguins')\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97aa697-ad53-4b5f-b9d8-8132e29ecc68",
   "metadata": {},
   "source": [
    "### How can we create a linear model which takes the ```sex``` variable into account?\n",
    "- One-Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91be8c62-a651-4aa7-8a3e-1e51219691de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda function time!\n",
    "# amazing Python feature\n",
    "df_penguins['is_male'] = df_penguins['sex'].apply(lambda x : int(x == 'Male'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b6ad5-9bdd-4beb-91cd-eefb364ebaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2ae5a0-2bad-4efa-b134-f579cff25550",
   "metadata": {},
   "source": [
    "Let's create a model here:\n",
    "\n",
    "$$\n",
    "Y_{mass} = \\beta_0 + \\beta_1 X_{flipper} + \\beta_2 X_{is\\_male}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b871c70-4c94-41ef-860c-cf9ea7e05aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(formula = 'body_mass_g ~ flipper_length_mm + is_male', data=df_penguins)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c820a95-33d3-40d2-b97d-80ba322320d0",
   "metadata": {},
   "source": [
    "## Lab 2\n",
    "\n",
    "1. Create a scatter plot with flipper length on the x-axis and body mass on the y-axis. Color the points according to the penguin's sex.\n",
    "2. Find the line of best fit for the penguins dataset to predict body mass from flipper length. Plot this on the plot from Q1.\n",
    "3. Find two lines of best fit: one for the male and one for the female penguins. Plot this on the plot from Q1.\n",
    "4. Take the line of best fit from above which used both flipper length and ```is_male```. Plot this line with $X_{is\\_male}=0$ and with $X_{is\\_male}=1$. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498ca41-fa33-4d4c-8fdc-1b8f223cb91a",
   "metadata": {},
   "source": [
    "## Next Time\n",
    "- Quiz 2 to start class\n",
    "- We'll talk about interpreting, evaluating, and troubleshooting your model.\n",
    "- Bootstrapping I hope!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e3b49-1012-4f54-8958-f2187df3d877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
