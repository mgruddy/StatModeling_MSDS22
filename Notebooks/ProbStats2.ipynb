{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a83a211",
   "metadata": {},
   "source": [
    "## Random integer between 1 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc98586",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 100000\n",
    "\n",
    "random_integers = np.random.randint(low=1, high=11, size=num_experiments)\n",
    "\n",
    "plt.hist(random_integers, bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711faa33",
   "metadata": {},
   "source": [
    "## Random number between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfdb70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "num_experiments = 1000\n",
    "for i in range(num_experiments):\n",
    "    values.append(random.random())\n",
    "\n",
    "plt.hist(values ,bins=20, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a615590d",
   "metadata": {},
   "source": [
    "## Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.normal(mean, std dev, size)\n",
    "ndst = np.random.normal(0,1,10000)\n",
    "ndst2 = np.random.normal(1,2,10000)\n",
    "ndst3 = np.random.normal(-2,0.5,10000)\n",
    "\n",
    "# if we don't call .show, it will put them all on the same plot!\n",
    "plt.hist(ndst, bins=30, alpha=0.5, density=True)\n",
    "plt.hist(ndst2, bins=30, alpha=0.5, density=True)\n",
    "plt.hist(ndst3, bins=30, alpha=0.5, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01763e8a",
   "metadata": {},
   "source": [
    "## Central Limit Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential distribution\n",
    "expdst = np.random.exponential(scale=1, size=10000)\n",
    "plt.hist(expdst, bins=30, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5\n",
    "num_experiments = 1000\n",
    "\n",
    "sample_means = []\n",
    "for i in range(num_experiments):\n",
    "    for j in range(sample_size):\n",
    "        sample = np.random.exponential(scale=1, size=sample_size)\n",
    "        sample_means.append(np.mean(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc6aa44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(sample_means, bins=30, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea4023-2dca-4854-a2c0-73b211747aa0",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "Let's take a look at a real dataset. Here is a master dataset of all the events and results from the Olympics. It can be found nicely pre-cleaned [here](https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results?select=athlete_events.csv) on Kaggle. You'll need a free account, which I encourage you to make if you have not done so already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cbf775-9bfa-4470-a313-78e46bc21862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the observations are various census tracts, or subregions of the USA\n",
    "df = pd.read_csv('data/athlete_events.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7369cc17-6d80-4cc9-a219-767e2082bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcffa3d-c0f4-40d2-8384-e58fd798291b",
   "metadata": {},
   "source": [
    "Take a second, play with the data. Explore it!\n",
    "- If you need a guiding question, try \"What is the mean height of an Olympic athlete from United States? Standard deviation?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1ecd2-2dac-4965-97b2-05a555877917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70a9dac6-5a0e-408c-897c-66a07cb00e72",
   "metadata": {},
   "source": [
    "Let's compare whether the mean height of Olympic athletes from another country differ from the United States. Suppose for the Netherlands our data is corrupted, and we have just a random sample of Olympic athletes rather than the whole population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086af165-a08d-49e2-b652-b0c3a1bf9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 0.5% of the athletes from the Netherlands\n",
    "df_sample = df[df['Team'] == 'Netherlands'].sample(frac=0.005)\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0fc2fa-7d92-482b-ba84-f5847724052e",
   "metadata": {},
   "source": [
    "This sets up the Hypothesis Test:\n",
    "\n",
    "$H_0: \\mu_{\\text{NED}} = 176$\n",
    "\n",
    "$H_a: \\mu_{\\text{NED}} \\neq 176$\n",
    "\n",
    "We *know* that means drawn from random samples are normally distributed by the Central Limit Theorem. By the Null Hypothesis we assume that this is a normal distribution has mean 176. Note that this is the mean of the distribution of the random variable $X$ where $X$ is the mean of a random sample of Bulgarian Olympic athlete heights. Let's set a significance level of $\\alpha = 0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c79f78-fb28-405c-9634-e93bfccf1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = df_sample['Height'].mean()\n",
    "sample_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39d4de-3396-452b-9530-af1a38805bee",
   "metadata": {},
   "source": [
    "How unusual is this result? Is it far enough away from the assumed fact to reject the Null Hypothesis?\n",
    "\n",
    "We estimate the standard deviation of this distribution to be $\\sigma_m = \\frac{\\sigma_{\\text{sample}}}{\\sqrt{n}}$. This is also known as the standard eror."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9da30f-c6f0-4bd5-ae57-0b817aee93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_error = scipy.stats.sem(df_sample['Height'], nan_policy='omit')\n",
    "std_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8502fa8-03f8-4288-942a-2b97abc60840",
   "metadata": {},
   "source": [
    "(remember this is the *sampling* distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f49e734-d364-4b6c-b845-92898355413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndst = np.random.normal(pop_mean, std_error, 100000)\n",
    "\n",
    "plt.hist(ndst, bins=30, density=True)\n",
    "\n",
    "# vertical line\n",
    "plt.axvline(x=sample_mean, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8db72c-8eed-4a4a-a80f-026c3a205ec4",
   "metadata": {},
   "source": [
    "Seems a bit unusual, but we can't be too sure! Time for statistics!\n",
    "1. How many standard deviations away from the population mean is our sample?\n",
    "2. What is the likelihood we draw a random sample from this population this far from the mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bb404-ac06-4091-9628-09483e39e846",
   "metadata": {},
   "source": [
    "Good news is that we know a lot about the standard normal distribution (remember mean 0 and std dev 1). We can convert our value to the standard normal as follows:\n",
    "\n",
    "$$\n",
    "Z = \\frac{\\bar{x} - \\mu}{\\sigma_m}\n",
    "$$\n",
    "\n",
    "This is known as a **z-score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed27a71-7ef9-4ba0-bcf2-f7ecbffbad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (sample_mean - pop_mean) / (std_error)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeea1dce-3a5b-4371-adaf-97a46e5eeb84",
   "metadata": {},
   "source": [
    "Assuming this distribution, our sample mean is about z standard deviations away from the regular mean. What's the likelihood of this occurring?\n",
    "\n",
    "$$\n",
    "P(Z < z) + P(Z > z)\n",
    "$$\n",
    "\n",
    "This is known as the **p-value**, the probability of obtaining this sample assuming that the null hypothesis is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94087086-3672-4c18-88a4-847f2227f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# this function gives the area under the standard normal distribution\n",
    "# to the left of the z value given\n",
    "def p_left_of_z(z):\n",
    "    return scipy.stats.norm(0, 1).cdf(z)\n",
    "\n",
    "ndst = np.random.normal(0, 1, 100000)\n",
    "plt.hist(ndst, bins=30, density=True)\n",
    "\n",
    "# In this plot we want the area to the left of left-most red line\n",
    "# and the right of the right-most red line\n",
    "plt.axvline(x=-z, color='red')\n",
    "plt.axvline(x=z, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4493ac-86d7-4e81-81c7-e1a2a911f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the distribution is symmetric we can just find\n",
    "# 2 times the area left of the left-most red line\n",
    "p = 2*p_of_z(-z)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c7a63-49ce-448d-b088-8de732a44699",
   "metadata": {},
   "source": [
    "This indicates that if the null hypothesis was true, this result would occur about *p*% of the time. Since we chose a significance level of $\\alpha=0.05$, if $p<\\alpha$ we reject the null hypothesis. Note that if we had been stricter before our experiment and chosen $\\alpha=0.01$ we may have gotten different results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29c472-7b3a-4e39-af01-a3a8286ae78d",
   "metadata": {},
   "source": [
    "## Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d531b137-9261-4e52-9cb9-f467c33bcc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_lvl = 0.95\n",
    "deg_of_freedom = len(df_sample) - 1\n",
    "\n",
    "confidence_interval = scipy.stats.t.interval(conf_lvl, deg_of_freedom, sample_mean, std_error)\n",
    "confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cfe86f-5f28-4169-8a32-f37863d4ada9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
